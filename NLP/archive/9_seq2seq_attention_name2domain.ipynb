{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize\n",
    "nltk.download('words')\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.utils.rnn import (\n",
    "    pack_padded_sequence, pad_packed_sequence, pad_sequence,\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Show better CUDA error messages\n",
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sb-airflow/flattened-profiles/prod/2019-06-27_@v0.7.10_flattened_profiles_full.jsonl data/flattened_profiles_full.jsonl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepsee_profiles = 'data/flattened_profiles_full.jsonl'\n",
    "deepsee_df = pd.read_json(deepsee_profiles, lines=True)\n",
    "df = deepsee_df[['company_domain', 'company_name']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Name2Domain Data\n",
    "\n",
    "class NameDomain(Dataset):\n",
    "    def __init__(self, path):\n",
    "        # Extra tokens to add\n",
    "        self.padding_token = '<PAD>'\n",
    "        self.start_of_sequence_token = '<SOS>'\n",
    "        self.end_of_sequence_token = '<EOS>'\n",
    "        self.unknown_word_token = '<UNK>'\n",
    "        \n",
    "        # load data\n",
    "        df = pd.read_json(path, lines=True)[['company_domain', 'company_name']]\n",
    "        \n",
    "        # Turn word sequence into discrete characters\n",
    "        df['chars_inputs'] = df.company_name.apply(NameDomain.char_split)\n",
    "        df['chars_targets'] = df.company_domain.apply(NameDomain.char_split)\n",
    "        \n",
    "        # Create charater to index mapping, and reverse\n",
    "        self.input_char2idx = self.create_char2idx(df.chars_inputs)\n",
    "        self.input_idx2char = {idx: char for char, idx in self.input_char2idx.items()}\n",
    "        self.target_char2idx = self.create_char2idx(df.chars_targets)\n",
    "        self.target_idx2char = {idx: char for char, idx in self.target_char2idx.items()}\n",
    "        \n",
    "        # Add start of sequence & end of sequence tokens\n",
    "        self.add_start_and_end_tokens(df)\n",
    "        \n",
    "        # Turn character sequences into indices\n",
    "        self.encode_sequence(df)\n",
    "        \n",
    "    \n",
    "    @staticmethod\n",
    "    def char_split(seq):\n",
    "        seq = list(seq.lower())\n",
    "        return [char for char in seq if char in string.printable]\n",
    "\n",
    "    \n",
    "    def get_unique_characters(self, sequences):\n",
    "        char_set = set()\n",
    "        for seq in sequences:\n",
    "            for char in seq:\n",
    "                char_set.add(char)\n",
    "        return char_set\n",
    "    \n",
    "    \n",
    "    def create_char2idx(self, sequences):\n",
    "        unique_characters = sorted(list(self.get_unique_characters(sequences)))\n",
    "        for token in [\n",
    "            self.start_of_sequence_token,\n",
    "            self.end_of_sequence_token,\n",
    "            self.padding_token,\n",
    "        ]:\n",
    "            unique_characters = [token] + unique_characters\n",
    "        return {char: idx for idx, char in enumerate(unique_characters)}\n",
    "    \n",
    "    \n",
    "    def add_start_and_end_tokens(self, df):\n",
    "        \"\"\"Add <SOS> and <EOS> tokens to the start & end of every input and output.\"\"\"\n",
    "        df.loc[:, 'chars_inputs'] = (\n",
    "            [self.start_of_sequence_token]\n",
    "            + df.chars_inputs\n",
    "            + [self.end_of_sequence_token]\n",
    "        )\n",
    "        df.loc[:, 'chars_targets'] = (\n",
    "            [self.start_of_sequence_token]\n",
    "            + df.chars_targets\n",
    "            + [self.end_of_sequence_token]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def encode_sequence(self, df):\n",
    "        \"\"\"Convert chars to indices.\"\"\"\n",
    "        df['indices_inputs'] = df.chars_inputs.apply(\n",
    "            lambda sequence: [self.input_char2idx[char] for char in sequence])\n",
    "        df['indices_targets'] = df.chars_targets.apply(\n",
    "            lambda sequence: [self.target_char2idx[char] for char in sequence])\n",
    "             \n",
    "        self.indices_pairs = list(zip(df.indices_inputs, df.indices_targets))\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.indices_pairs[i][0], self.indices_pairs[i][1]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NameDomain('data/flattened_profiles_full.jsonl')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.input_char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Split train, validation, and test\n",
    "\n",
    "def split_train_valid_test(corpus, valid_ratio=0.1, test_ratio=0.1):\n",
    "    \"\"\"Split dataset into train, validation, and test.\"\"\"\n",
    "    test_length = int(len(corpus) * test_ratio)\n",
    "    valid_length = int(len(corpus) * valid_ratio)\n",
    "    train_length = len(corpus) - valid_length - test_length\n",
    "    return random_split(\n",
    "        corpus, lengths=[train_length, valid_length, test_length],\n",
    "    )\n",
    "\n",
    "valid_ratio = 0.1  #@param {type:\"slider\", min:0.01, max:0.3, step:0.01}\n",
    "test_ratio = 0.1  #@param {type:\"slider\", min:0.001, max:0.3, step:0.01}\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = split_train_valid_test(\n",
    "    dataset,\n",
    "    valid_ratio=valid_ratio,\n",
    "    test_ratio=test_ratio,\n",
    ")\n",
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Generate batches\n",
    "\n",
    "def collate(batch):\n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    \n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\n",
    "    padded_inputs = pad_sequence(\n",
    "        inputs, \n",
    "        padding_value=dataset.input_char2idx[dataset.padding_token], \n",
    "        batch_first=True,\n",
    "    )\n",
    "    padded_targets = pad_sequence(\n",
    "        targets, \n",
    "        padding_value=dataset.target_char2idx[dataset.padding_token], \n",
    "        batch_first=True\n",
    "    )\n",
    "    \n",
    "    # Sort by length for CUDA optimizations\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\n",
    "\n",
    "# Powers of two are preferred for optimal usage on the GPU\n",
    "batch_size = 512  #@param {type:\"integer\"}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, char_set_size, embedding_dim, hidden_size, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.char_set_size = char_set_size\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.char_set_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding_dim,\n",
    "            self.hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        # Turn input indices into distributed embeddings\n",
    "        x = self.embedding(inputs)\n",
    "\n",
    "        # Remove padding for more efficient RNN application\n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "    \n",
    "        # Apply RNN to get hidden state at all timesteps (output)\n",
    "        # and hidden state of last output (self.hidden)\n",
    "        output, self.hidden = self.gru(x, self.init_hidden())\n",
    "        \n",
    "        # Pad the sequences like they were before\n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output, self.hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn((1, self.batch_size, self.hidden_size)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        char_set_size,\n",
    "        embedding_dim, \n",
    "        decoder_hidden_size,\n",
    "        encoder_hidden_size, \n",
    "        batch_size,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.char_set_size = char_set_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(self.char_set_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(\n",
    "            self.embedding_dim + self.encoder_hidden_size, \n",
    "            self.decoder_hidden_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.encoder_hidden_size, self.char_set_size)\n",
    "        \n",
    "        # Attention weights\n",
    "        self.W1 = nn.Linear(self.encoder_hidden_size, self.decoder_hidden_size)\n",
    "        self.W2 = nn.Linear(self.encoder_hidden_size, self.decoder_hidden_size)\n",
    "        self.V = nn.Linear(self.encoder_hidden_size, 1)\n",
    "    \n",
    "    def forward(self, targets, hidden, encoder_output):\n",
    "        # Switch the dimensions of sequence_length and batch_size\n",
    "        encoder_output = encoder_output.permute(1, 0, 2)\n",
    "\n",
    "        # Add an extra axis for a time dimension\n",
    "        hidden_with_time_axis = hidden.permute(1, 0, 2)\n",
    "        \n",
    "        # Attention score (Bahdanaus)\n",
    "        score = torch.tanh(self.W1(encoder_output) + self.W2(hidden_with_time_axis))\n",
    "\n",
    "        # Attention weights\n",
    "        attention_weights = torch.softmax(self.V(score), dim=1)\n",
    "        \n",
    "        # Find the context vectors\n",
    "        context_vector = attention_weights * encoder_output\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "        \n",
    "        # Turn target indices into distributed embeddings\n",
    "        x = self.embedding(targets)\n",
    "        \n",
    "        # Add the context representation to the target embeddings\n",
    "        x = torch.cat((context_vector.unsqueeze(1), x), -1)\n",
    "        \n",
    "        # Apply the RNN\n",
    "        output, state = self.gru(x, self.init_hidden())\n",
    "        \n",
    "        # Reshape the hidden states (output)\n",
    "        output = output.view(-1, output.size(2))\n",
    "        \n",
    "        # Apply a linear layer\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Randomly initialize the weights of the RNN\n",
    "        return torch.randn((1, self.batch_size, self.decoder_hidden_size)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"Calculate how wrong the model is.\"\"\"\n",
    "    # Use mask to only consider non-zero inputs in the loss\n",
    "    mask = real.ge(1).float().to(device)\n",
    "    \n",
    "    loss_ = criterion(pred, real) * mask \n",
    "    return torch.mean(loss_)\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_char_set_size,\n",
    "        target_char_set_size,\n",
    "        hidden_size,\n",
    "        embedding_dim, \n",
    "        batch_size,\n",
    "        targets_start_idx,\n",
    "        targets_stop_idx,\n",
    "    ):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.targets_start_idx = targets_start_idx\n",
    "        self.targets_stop_idx = targets_stop_idx\n",
    "        \n",
    "        self.encoder = Encoder(\n",
    "            input_char_set_size,\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "        self.decoder = Decoder(\n",
    "            target_char_set_size,\n",
    "            embedding_dim,\n",
    "            hidden_size,\n",
    "            hidden_size,\n",
    "            batch_size,\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, inputs, targets, lengths, predict=False):\n",
    "        encoder_output, encoder_hidden = self.encoder(\n",
    "            inputs.to(device),\n",
    "            lengths,\n",
    "        )\n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        # Initialize the input of the decoder to be <SOS>\n",
    "        decoder_input = torch.LongTensor(\n",
    "            [[self.targets_start_idx]] * self.batch_size,\n",
    "        )\n",
    "        \n",
    "        if predict:\n",
    "            # Output predictions instead of loss\n",
    "            output = []\n",
    "            for _ in range(20):\n",
    "                predictions, decoder_hidden, _ = self.decoder(\n",
    "                    decoder_input.to(device), \n",
    "                    decoder_hidden.to(device),\n",
    "                    encoder_output.to(device),\n",
    "                )\n",
    "                prediction = torch.multinomial(F.softmax(predictions, dim=1), 1)\n",
    "                decoder_input = prediction\n",
    "\n",
    "                prediction = prediction.item()\n",
    "                output.append(prediction)\n",
    "                \n",
    "                if prediction == self.targets_stop_idx:\n",
    "                    return output\n",
    "\n",
    "            return output\n",
    "                \n",
    "        # Use teacher forcing to train the model. Instead of feeding the model's\n",
    "        # own predictions to itself, feed the target token at every timestep.\n",
    "        # This leads to faster convergence\n",
    "        loss = 0\n",
    "        for timestep in range(1, targets.size(1)):\n",
    "            predictions, decoder_hidden, _ = self.decoder(\n",
    "                decoder_input.to(device), \n",
    "                decoder_hidden.to(device),\n",
    "                encoder_output.to(device),\n",
    "            )\n",
    "            decoder_input = targets[:, timestep].unsqueeze(1)\n",
    "            \n",
    "            loss += loss_function(targets[:, timestep], predictions)\n",
    "            \n",
    "        return loss / targets.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer, scheduler, train_loader):\n",
    "    model.train()\n",
    "    total_loss = total = 0\n",
    "    progress_bar = tqdm_notebook(train_loader, desc='Training', leave=False)\n",
    "    for inputs, targets, lengths in progress_bar:\n",
    "        # Clean old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwards pass\n",
    "        loss = model(inputs, targets, lengths)\n",
    "\n",
    "        # Perform gradient descent, backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a step in the right direction\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Record metrics\n",
    "        total_loss += loss.item()\n",
    "        total += targets.size(1)\n",
    "\n",
    "    return total_loss / total\n",
    "\n",
    "\n",
    "def validate_epoch(model, valid_loader):\n",
    "    model.eval()\n",
    "    total_loss = total = 0\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm_notebook(valid_loader, desc='Validating', leave=False)\n",
    "        for inputs, targets, lengths in progress_bar:\n",
    "            # Forwards pass\n",
    "            loss = model(inputs, targets, lengths)\n",
    "\n",
    "            # Record metrics\n",
    "            total_loss += loss.item()\n",
    "            total += targets.size(1)\n",
    "\n",
    "    return total_loss / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_char_set_size = len(dataset.input_char2idx)\n",
    "target_char_set_size = len(dataset.target_char2idx)\n",
    "targets_start_idx = dataset.target_char2idx[dataset.start_of_sequence_token]\n",
    "targets_stop_idx = dataset.target_char2idx[dataset.end_of_sequence_token]\n",
    "\n",
    "hidden_size = 128  #@param {type:\"integer\"}\n",
    "embedding_dim = 128  #@param {type:\"integer\"}\n",
    "learning_rate = 0.001  #@param {type:\"number\"}\n",
    "max_epochs = 50  #@param {type:\"integer\"}\n",
    "\n",
    "# Instantiate a model to train\n",
    "model = EncoderDecoder(\n",
    "    input_char_set_size,\n",
    "    target_char_set_size,\n",
    "    hidden_size, \n",
    "    embedding_dim, \n",
    "    batch_size, \n",
    "    targets_start_idx, \n",
    "    targets_stop_idx,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "scheduler = CosineAnnealingLR(optimizer, 1)\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 0\n",
    "train_losses, valid_losses = [], []\n",
    "for _ in range(max_epochs):\n",
    "    train_loss = train_epoch(model, optimizer, scheduler, train_loader)\n",
    "    valid_loss = validate_epoch(model, valid_loader)\n",
    "    \n",
    "    tqdm.write(\n",
    "        f'epoch #{n_epochs + 1:3d}\\ttrain_loss: {train_loss:.2e}'\n",
    "        f'\\tvalid_loss: {valid_loss:.2e}\\n',\n",
    "    )\n",
    "    \n",
    "    # Early stopping if the current valid_loss is greater than the\n",
    "    # last three valid losses\n",
    "    if len(valid_losses) > 2 and all(valid_loss >= loss\n",
    "                                     for loss in valid_losses[-3:]):\n",
    "        print('Stopping early')\n",
    "        break\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    n_epochs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ticks = range(1, n_epochs + 1)\n",
    "plt.plot(epoch_ticks, train_losses)\n",
    "plt.plot(epoch_ticks, valid_losses)\n",
    "plt.legend(['Train Loss', 'Valid Loss'])\n",
    "plt.title('Losses') \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(epoch_ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoder(\n",
    "    input_char_set_size, \n",
    "    target_char_set_size, \n",
    "    hidden_size, \n",
    "    embedding_dim,\n",
    "    1,\n",
    "    targets_start_idx,\n",
    "    targets_stop_idx,\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_loss = total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets, lengths in test_loader:\n",
    "        print('>', ''.join([\n",
    "            dataset.input_idx2char[idx]\n",
    "            for idx in inputs.cpu()[0].numpy()[1:-1]\n",
    "        ]))\n",
    "\n",
    "        # Forwards pass\n",
    "        outputs = model(inputs, targets, lengths, predict=True)\n",
    "        print(''.join([\n",
    "            dataset.target_idx2char[idx]\n",
    "            for idx in outputs[:-1]\n",
    "        ]))\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
